# render.yaml
# Render Blueprint configuration for free deployment

services:
  # Web Service Configuration
  - type: web
    name: rag-policy-chatbot
    env: python
    region: oregon
    plan: free
    
    # Build configuration - using free models, no API keys needed
    buildCommand: |
      pip install -r requirements.txt
      python -c 'from src.ingestion import DocumentIngestion; DocumentIngestion().ingest_all()'
    
    # Start configuration
    startCommand: gunicorn app:app --bind 0.0.0.0:$PORT --workers 1 --threads 2 --timeout 120 --worker-class gthread
    
    # Health check configuration
    healthCheckPath: /health
    
    # Auto-deploy configuration
    branch: main
    
    # Environment variables (all free, no API keys needed)
    envVars:
      - key: PYTHON_VERSION
        value: 3.10.0
      
      # Using Groq free API (no credit card required)
      - key: USE_GROQ
        value: true
      
      - key: GROQ_API_KEY
        sync: false  # Set this in Render dashboard (free key from groq.com)
      
      - key: GROQ_MODEL
        value: llama-3.1-8b-instant
      
      # Embedding model - small and fast
      - key: EMBEDDING_MODEL
        value: sentence-transformers/all-MiniLM-L6-v2
      
      - key: CHUNK_SIZE
        value: 400
      
      - key: CHUNK_OVERLAP
        value: 40
      
      - key: TOP_K
        value: 3
      
      - key: MAX_TOKENS
        value: 400
      
      - key: TEMPERATURE
        value: 0.3
      
      - key: DEBUG
        value: False
      
      - key: PORT
        generateValue: true